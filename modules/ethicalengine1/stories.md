---
layout: page
title: Person Model - Stories
exclude: true
---
![university](img/people.jpg)

## From Teluta to Facebook
In part 1 of your work, we situated you as a worker of a hypothetical company called _Teluta_. But real-world companies constantly collect and represent our personal characteristics - at times, with terrible consequences. Read the stories below about instances about real companies...

_What are the potential consequences of including characteristics in code?_
- [Facebook Lets Advertisers Exclude Users by Race](https://www.propublica.org/article/facebook-lets-advertisers-exclude-users-by-race)
- [Dozens of Companies are Using Facebook to Exclude Older Workers from Job Ads](https://www.propublica.org/article/facebook-ads-age-discrimination-targeting)

_What are the possible challenges of inferring characteristics?_
- [Facial Recognition is Accurate, if You're a White Guy](https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)


### Reflection Questions

- Imagine that _Teluta_ cars tried to infer your characteristics on-the-fly using a suite of state-of-the-art sensors. Do you think that any of your characteristics could be misclassified?  What would the implications of that misclassification be?

- While you currently trust the leadership at _Teluta_, what if more morally dubious (or oblivious?) leaders took over the company after you had left. Do you think that any of your design decisions could be abused by the company? How?

- Given this reflection, which characteristics would you remove from your code? Why?

- Are there any tradeoffs to removing too many characteristics from _Teluta_'s code? What are they?
